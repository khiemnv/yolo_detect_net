<!DOCTYPE html>
<html>
    <head>
        <title>ONNX Runtime JavaScript examples: Quick Start - Web (using script tag)</title>
    </head>
    <style>
        .row {
            display: flex;
            flex-direction: row;
        }

        .col {
            display: flex;
            flex-direction: column;
            align-items: flex-start;
        }
    </style>
    <div class="row">
        <div class="col">
            <label>circle</label>
            <img id="circle_img" src="100.jpg">
            <button id="detect_btn">detect</button>
        </div>
        <div class="col">
            <label>eclipse</label>
            <img id="eclipse_img" src="135x83.jpg">
            <button id="detect_btn2">detect</button>
        </div>
    </div>
    <div>
        <canvas id="resized_ctx" style="display: none;"></canvas>
    </div>
    <div>
        <pre id="output_txt"></pre>
    </div>
    <body>
        <!-- see also advanced usage of importing ONNX Runtime Web: -->
        <!-- https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/importing_onnxruntime-web -->

        <!-- import ONNXRuntime Web from CDN -->
        <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
        <script>
            // use an async context to call onnxruntime functions.
            async function main() {
                try {
                    // create a new session and load the specific model.
                    //
                    // the model in this example contains a single MatMul node
                    // it has 2 inputs: 'a'(float32, 3x4) and 'b'(float32, 4x3)
                    // it has 1 output: 'c'(float32, 3x3)
                    const session = await ort.InferenceSession.create('./model.onnx');

                    // prepare inputs. a tensor need its corresponding TypedArray as data
                    const dataA = Float32Array.from([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]);
                    const dataB = Float32Array.from([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]);
                    const tensorA = new ort.Tensor('float32', dataA, [3, 4]);
                    const tensorB = new ort.Tensor('float32', dataB, [4, 3]);

                    // prepare feeds. use model input names as keys.
                    const feeds = { a: tensorA, b: tensorB };

                    // feed inputs and run
                    const results = await session.run(feeds);

                    // read from results
                    const dataC = results.c.data;
                    document.write(`data of result tensor 'c': ${dataC}`);

                } catch (e) {
                    document.write(`failed to inference ONNX model: ${e}.`);
                }
            }

            // main();
        </script>
        <script src="index.js"></script>
    </body>
</html>
